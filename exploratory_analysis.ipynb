{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiate session\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"explorer\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('crime_id', StringType(), False),\n",
    "    StructField('original_crime_type_name', StringType()),\n",
    "    StructField('report_date', StringType()),\n",
    "    StructField('call_date', StringType()),\n",
    "    StructField('offense_date', StringType()),\n",
    "    StructField('call_time', StringType()),\n",
    "    StructField('call_date_time', StringType()),\n",
    "    StructField('disposition', StringType()),\n",
    "    StructField('address', StringType()),\n",
    "    StructField('city', StringType()),\n",
    "    StructField('state', StringType()),\n",
    "    StructField('agency_id', StringType()),\n",
    "    StructField('address_type', StringType()),\n",
    "    StructField('common_location', StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199999\n",
      "{'crime_id': '183653763', 'original_crime_type_name': 'Traffic Stop', 'report_date': '2018-12-31T00:00:00.000', 'call_date': '2018-12-31T00:00:00.000', 'offense_date': '2018-12-31T00:00:00.000', 'call_time': '23:57', 'call_date_time': '2018-12-31T23:57:00.000', 'disposition': 'ADM', 'address': 'Geary Bl/divisadero St', 'city': 'San Francisco', 'state': 'CA', 'agency_id': '1', 'address_type': 'Intersection', 'common_location': ''}\n"
     ]
    }
   ],
   "source": [
    "input_file='./police-department-calls-for-service.json'\n",
    "with open(input_file) as fp:\n",
    "    data = json.load(fp)\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#spark.parallelize(json.dumps(data[:5]))\n",
    "df = spark.createDataFrame(data[:1000], schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- crime_id: string (nullable = false)\n",
      " |-- original_crime_type_name: string (nullable = true)\n",
      " |-- report_date: string (nullable = true)\n",
      " |-- call_date: string (nullable = true)\n",
      " |-- offense_date: string (nullable = true)\n",
      " |-- call_time: string (nullable = true)\n",
      " |-- call_date_time: string (nullable = true)\n",
      " |-- disposition: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- agency_id: string (nullable = true)\n",
      " |-- address_type: string (nullable = true)\n",
      " |-- common_location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "def get_shape(df):\n",
    "    \"\"\" Gets dataframe shape\n",
    "    \n",
    "    Args:\n",
    "        df (pyspark.sql.dataframe.DataFrame): Spark dataframe\n",
    "    \n",
    "    Returns: \n",
    "        (row count, column count) tuple\n",
    "    \n",
    "    Assistance from here: https://stackoverflow.com/questions/39652767/pyspark-2-0-the-size-or-shape-of-a-dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    return (df.count(), len(df.columns))\n",
    "\n",
    "print(\"Shape: {}\".format(get_shape(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+--------------------+--------------------+--------------------+---------+--------------------+-----------+--------------------+-------------+-----+---------+---------------+--------------------+\n",
      "| crime_id|original_crime_type_name|         report_date|           call_date|        offense_date|call_time|      call_date_time|disposition|             address|         city|state|agency_id|   address_type|     common_location|\n",
      "+---------+------------------------+--------------------+--------------------+--------------------+---------+--------------------+-----------+--------------------+-------------+-----+---------+---------------+--------------------+\n",
      "|183653763|            Traffic Stop|2018-12-31T00:00:...|2018-12-31T00:00:...|2018-12-31T00:00:...|    23:57|2018-12-31T23:57:...|        ADM|Geary Bl/divisade...|San Francisco|   CA|        1|   Intersection|                    |\n",
      "|183653756|     Traf Violation Cite|2018-12-31T00:00:...|2018-12-31T00:00:...|2018-12-31T00:00:...|    23:54|2018-12-31T23:54:...|        CIT|   100 Blk Howard St|San Francisco|   CA|        1|   Geo-Override|                    |\n",
      "|183653746|            Passing Call|2018-12-31T00:00:...|2018-12-31T00:00:...|2018-12-31T00:00:...|    23:49|2018-12-31T23:49:...|        HAN|3300 Block Of 20t...|San Francisco|   CA|        1|Common Location|Stonestown Galler...|\n",
      "|183653745|           Audible Alarm|2018-12-31T00:00:...|2018-12-31T00:00:...|2018-12-31T00:00:...|    23:47|2018-12-31T23:47:...|        PAS|1900 Block Of 18t...|San Francisco|   CA|        1|Premise Address|                    |\n",
      "|183653737|            Traffic Stop|2018-12-31T00:00:...|2018-12-31T00:00:...|2018-12-31T00:00:...|    23:46|2018-12-31T23:46:...|        CIT|Sansome St/chestn...|San Francisco|   CA|        1|   Intersection|                    |\n",
      "+---------+------------------------+--------------------+--------------------+--------------------+---------+--------------------+-----------+--------------------+-------------+-----+---------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts:\n",
      "+--------+------------------------+-----------+---------+------------+---------+--------------+-----------+-------+----+-----+---------+------------+---------------+\n",
      "|crime_id|original_crime_type_name|report_date|call_date|offense_date|call_time|call_date_time|disposition|address|city|state|agency_id|address_type|common_location|\n",
      "+--------+------------------------+-----------+---------+------------+---------+--------------+-----------+-------+----+-----+---------+------------+---------------+\n",
      "|       0|                       0|          0|        0|           0|        0|             0|          0|      0|   0|    0|        0|           0|              0|\n",
      "+--------+------------------------+-----------+---------+------------+---------+--------------+-----------+-------+----+-----+---------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_null_counts(df):\n",
    "    \"\"\" \n",
    "    Args: \n",
    "        df (pyspark.sql.dataframe.DataFrame): Spark dataframe\n",
    "        \n",
    "    Assistance from here: https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return df.select(\n",
    "            [F.count(\n",
    "                F.when(F.isnan(c) | F.isnull(c), 1)\n",
    "            ).alias(c) for c in df.columns]\n",
    "        )\n",
    "    except:\n",
    "        return df.select(\n",
    "            [F.count(\n",
    "                F.when(F.isnull(c), 1)\n",
    "            ).alias(c) for c in df.columns]\n",
    "        )\n",
    "\n",
    "print(\"Null counts:\")\n",
    "get_null_counts(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
